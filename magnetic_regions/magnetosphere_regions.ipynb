{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetosphere region classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speasy as spz\n",
    "import sklearn\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "# locally defined functions\n",
    "import speasy_utils.amda as amda_utils\n",
    "#import amda_utils\n",
    "\n",
    "# default format for datetime objects\n",
    "date_fmt=\"%Y-%m-%dT%H:%M:%S\"\n",
    "# excess time for interpolation\n",
    "delta_t = timedelta(days=1)\n",
    "# ACE data timeshift\n",
    "shift_t = timedelta(seconds=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start and stop times\n",
    "We want at least a year's worth of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start, stop = \"2007-03-01T00:00:00\", \"2008-03-01T00:00:00\"\n",
    "start, stop = \"2007-03-01T00:00:00\", \"2009-04-01T00:00:00\"\n",
    "start, stop = datetime.strptime(start, date_fmt), \\\n",
    "    datetime.strptime(stop, date_fmt)\n",
    "# used for naming data file\n",
    "start_str, stop_str = start.strftime(date_fmt),stop.strftime(date_fmt)\n",
    "# start and stop for getting data\n",
    "start_d, stop_d = start - delta_t, stop + delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_ids = [\"thb_n_i\",\"thb_bs\",\"imf\",\"sw_n\",\"thb_xyz\",\n",
    "                \"tha_n_i\",\"tha_bs\",\"tha_xyz\"]\n",
    "m = len(parameter_ids)\n",
    "parameter_shifts = {\"imf\":shift_t, \"sw_n\":shift_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param:amda/thb_bs |█████████████████████-----------------------------| 43.0%  \r"
     ]
    }
   ],
   "source": [
    "data_filename = f\"parameter_data_{start_str}_{stop_str}.pkl\"\n",
    "\n",
    "parameter_data = amda_utils.get_parameter_data(parameter_ids, \n",
    "                                    start_d,\n",
    "                                    stop_d,\n",
    "                                    data_filename, \n",
    "                                    shifts=parameter_shifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ID shape nans\")\n",
    "for k in parameter_data:\n",
    "    print(k, parameter_data[k].data.shape,\\\n",
    "          np.isnan(parameter_data[k].data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(len(parameter_ids), 1, figsize=(10,10))\n",
    "for (k,p),ax in zip(parameter_data.items(),axes):\n",
    "    ax.plot(p.time, p.data)\n",
    "    ax.set_title(k)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "def clean_data(y):\n",
    "    nans, x= nan_helper(y)\n",
    "    y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    return y\n",
    "\n",
    "for k in parameter_data:\n",
    "    if np.any(np.isnan(parameter_data[k].data)):\n",
    "        new_data = clean_data(parameter_data[k].data)\n",
    "        parameter_data[k].data = new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(len(parameter_ids), 1, figsize=(10,m*5))\n",
    "for (k,p),ax in zip(parameter_data.items(),axes):\n",
    "    ax.plot(p.time, p.data)\n",
    "    ax.set_title(k)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "interp_data = {}\n",
    "\n",
    "for k in parameter_data:\n",
    "    interp_data[k] = interp1d(parameter_data[k].time, parameter_data[k].data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [None, None]\n",
    "for k in parameter_data:\n",
    "    t = parameter_data[k].time\n",
    "    if bounds[0] is None or np.min(t)>bounds[0]:\n",
    "        bounds[0] = np.min(t)\n",
    "    if bounds[1] is None or np.max(t)<bounds[1]:\n",
    "        bounds[1] = np.max(t)\n",
    "bounds = [datetime.fromtimestamp(e) for e in bounds]\n",
    "print(f\"Interpolation bounds : {bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.date_range(bounds[0]+delta_t,bounds[1]-delta_t,freq=\"60S\").astype(np.int64)/1e9\n",
    "interpolated_data = {}\n",
    "for k in parameter_data:\n",
    "    interpolated_data[k]=interp_data[k](t)\n",
    "\n",
    "f, axes = plt.subplots(len(parameter_ids), 1, figsize=(10,10))\n",
    "for (k,p),ax in zip(parameter_data.items(),axes):\n",
    "    ax.plot(t, interpolated_data[k])\n",
    "    ax.set_title(k)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_ace = np.linalg.norm(interpolated_data[\"imf\"], axis=1)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t, B_ace)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "B_tha = np.linalg.norm(interpolated_data[\"thb_bs\"], axis=1)\n",
    "plt.plot(t, B_tha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ace = interpolated_data[\"sw_n\"]\n",
    "n_tha = interpolated_data[\"thb_n_i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_b = B_tha / B_ace\n",
    "r_n = (n_tha / n_ace).flatten()\n",
    "print(n_tha.shape)\n",
    "print(np.sum(n_tha < 0.))\n",
    "\n",
    "f, axes = plt.subplots(2,1)\n",
    "axes[0].plot(r_b)\n",
    "axes[1].plot(r_n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.isnan(r_b)), np.sum(np.isnan(r_n)))\n",
    "cmap=\"gist_stern\"\n",
    "esp= 1.e-1\n",
    "#plt.hist2d(r_n, r_b, bins=1000, range=domain,cmap=cmap)\n",
    "print(np.sum(np.isnan(r_n)), np.sum(np.isnan(r_b)))\n",
    "print(np.sum(np.isinf(r_n)), np.sum(np.isinf(r_b)))\n",
    "print(r_n.min(),r_n.max(), r_b.min(), r_b.max())\n",
    "plt.hist2d(r_n, r_b, bins=1000, range=None,cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp= 1.e-1\n",
    "#domain = np.array([[0,8],[0,30]])\n",
    "#domain_ = np.log(1+domain)\n",
    "#hist_data = plt.hist2d(np.log(1+r_n), np.log(1+r_b), bins=1000, range=domain_,cmap=cmap)\n",
    "hist_data = plt.hist2d(np.log(1+r_n), np.log(1+r_b), bins=1000, range=None,cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_data[0].sum(axis=1))\n",
    "plt.plot(hist_data[0].sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=hist_data[0].sum(axis=0),hist_data[0].sum(axis=1)\n",
    "plt.hist(1./(1.e-1+a/a.max()),alpha=.3,bins=100)\n",
    "#plt.hist(1./(1+np.exp(-b/b.max())),alpha=.3,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=(a-np.mean(a))/np.std(a)\n",
    "bb=(b-np.mean(b))/np.std(b)\n",
    "plt.hist(aa,alpha=.5,bins=50)\n",
    "plt.hist(bb,alpha=.5,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"solar_wind\", \"magnetosheath\", \"magnetopause\"]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,random_state=0)\n",
    "x_train = np.vstack((np.log(1+r_n),np.log(1+r_b))).T\n",
    "print(x_train.shape)\n",
    "kmeans=kmeans.fit(x_train)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "plt.figure()\n",
    "#plt.hist2d(np.log(1+r_n), np.log(1+r_b), bins=1000, range=domain_,cmap=cmap)\n",
    "plt.hist2d(np.log(1+r_n), np.log(1+r_b), bins=1000, range=None,cmap=cmap)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_region(x, y, clf, ax):\n",
    "    x_min, x_max = x[:,0].min(), x[:,0].max()\n",
    "    y_min, y_max = x[:,1].min(), x[:,1].max()\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, .1),\n",
    "                        np.arange(y_min,y_max,.1))\n",
    "    z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    z = z.reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, z, alpha=.4)\n",
    "    if y is not None:\n",
    "        yx, yy = y\n",
    "        ax.scatter(yx[:,0], yx[:,1], c=yy, s=20, edgecolor=\"k\")\n",
    "    \n",
    "    if hasattr(clf, \"cluster_centers_\" ):\n",
    "        c=0\n",
    "        for cc in clf.cluster_centers_:\n",
    "            ax.text(cc[0],cc[1],str(c))\n",
    "            c+=1\n",
    "    return ax\n",
    "\n",
    "fig=plt.figure()\n",
    "plot_decision_region(x_train,None,kmeans,fig.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "def domain_contains(x, domain):\n",
    "    if domain is None:\n",
    "        return True\n",
    "    if np.any(np.isnan(x)):\n",
    "        return False\n",
    "    for i in np.arange(x.shape[0]):\n",
    "        if x[i] < domain[i][0] or x[i]>domain[i][1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def normalize(x):\n",
    "    r= (x - np.mean(x)) / np.std(x)\n",
    "    return r\n",
    "\n",
    "r_b_log, r_n_log = np.log(1+r_b), np.log(1+r_n)\n",
    "r_b_mean, r_b_std = np.mean(r_b_log), np.std(r_b_log)\n",
    "r_n_mean, r_n_std = np.mean(r_n_log), np.std(r_n_log)\n",
    "\n",
    "r_b_norm = normalize(r_b_log)\n",
    "r_n_norm = normalize(r_n_log)\n",
    "\n",
    "# domain correction\n",
    "#domain[0] = (domain[0]-r_n_mean) / r_n_std\n",
    "#domain[1] = (domain[1]-r_b_mean) / r_b_std\n",
    "domain = None\n",
    "\n",
    "#x_train = np.vstack((r_n,r_b)).T\n",
    "x_train = np.vstack((r_n_norm, r_b_norm)).T\n",
    "index = np.apply_along_axis(lambda x: domain_contains(x,domain), 1, x_train)\n",
    "x_train = x_train[index]\n",
    "print(f\"x_train.shape : {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.hist2d(np.log(1+x_train[:,0]), np.log(1+x_train[:,1]), bins=1000, range=None,cmap=cmap)\n",
    "plt.hist2d(x_train[:,0], x_train[:,1], bins=1000, range=None,cmap=cmap)\n",
    "\n",
    "for n_c in [3,6,9]:\n",
    "    print(f\"n_clusters : {n_c}\")\n",
    "    kmeans = KMeans(n_clusters=n_c,random_state=0).fit(x_train)\n",
    "    plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],label=f\"n:{n_c}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision regions for KMeans(6)\n",
    "#kmeans = KMeans(n_clusters=6,random_state=0).fit(np.log(1+x_train))\n",
    "kmeans = KMeans(n_clusters=6,random_state=0).fit(x_train)\n",
    "fig=plt.figure()\n",
    "plot_decision_region(x_train,None,kmeans,fig.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0: [5], 1: [0,3,4], 2: [1,2]}\n",
    "#x_train_log = np.log(1+x_train)\n",
    "def map_classes(y, m):\n",
    "    yr = y.copy()\n",
    "    for k in m:\n",
    "        for ic in m[k]:\n",
    "            yr = np.where(y==ic, k, yr)\n",
    "    return yr\n",
    "\n",
    "y_train_ = kmeans.predict(x_train)\n",
    "y_train = map_classes(y_train_, class_map)\n",
    "plt.figure()\n",
    "plt.hist(y_train_,alpha=.5,density=True)\n",
    "plt.hist(y_train, alpha=.5,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "print(f\"x_train.shape : {x_train.shape}\")\n",
    "from sklearn.cluster import DBSCAN\n",
    "r_indx = np.arange(0,x_train.shape[0],100)\n",
    "r_indx = np.random.choice(range(x_train.shape[0]), size=r_indx.shape[0])\n",
    "x_train_rand = x_train[r_indx]\n",
    "db = DBSCAN(eps=.3, leaf_size=8,).fit(x_train_rand)\n",
    "\n",
    "# Spectral\n",
    "from sklearn.cluster import SpectralClustering\n",
    "spct = SpectralClustering(n_clusters=5)\n",
    "spct_z = spct.fit_predict(x_train_rand)\n",
    "\n",
    "\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "\n",
    "fig=plt.figure()\n",
    "ax = fig.gca()\n",
    "#plot_decision_region(x_train,None,clst,fig.gca())\n",
    "#plt.show()\n",
    "\n",
    "x_min, x_max = x_train_rand[:,0].min(), x_train_rand[:,0].max()\n",
    "y_min, y_max = x_train_rand[:,1].min(), x_train_rand[:,1].max()\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .1),\n",
    "                        np.arange(y_min,y_max,.1))\n",
    "z = labels #clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "print(np.c_[xx.ravel(), yy.ravel()].shape)\n",
    "\n",
    "#db = DBSCAN(leaf_size=8,).fit(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = db.labels_\n",
    "n_clusters_ = len(set(z)) - (1 if -1 in z else 0)\n",
    "print(f\"n_clusters : {n_clusters_}\")\n",
    "#z = z.reshape(xx.shape)\n",
    "#z = z.reshape(xx.shape)\n",
    "    \n",
    "ax.scatter(x_train_rand[:,0], x_train_rand[:,1], c=z, alpha=.4)\n",
    "\n",
    "plt.figure()\n",
    "plt.gca().scatter(x_train_rand[:,0], x_train_rand[:,1], c=spct_z, alpha=.4)\n",
    "#zz = spct.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "#zz = zz.reshape(xx.shape)\n",
    "#plt.gca().contourf(xx,yy, zz)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(z.flatten(), bins=20, alpha=.4)\n",
    "plt.hist(spct_z.flatten(), bins=20, alpha=.4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# blob\n",
    "blob_indx = (z == 0)\n",
    "#plt.scatter(x_train_rand[blob_indx,0], x_train_rand[blob_indx,1])\n",
    "blob_x_train = x_train_rand[blob_indx]\n",
    "\n",
    "db = DBSCAN(eps=.2, leaf_size=30,).fit(blob_x_train)\n",
    "db_z = db.labels_\n",
    "spct_z = SpectralClustering().fit_predict(blob_x_train)\n",
    "\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "n_noise_ = list(db.labels_).count(-1)\n",
    "print(\"DBSCAN\")\n",
    "print(\"\\tnumber of clusters: %d\" % n_clusters_)\n",
    "print(\"\\tnumber of noise points: %d\" % n_noise_)\n",
    "\n",
    "# Number of clusters in labels, SpectralClustering\n",
    "n_clusters_ = len(set(spct_z)) - (1 if -1 in spct_z else 0)\n",
    "n_noise_ = list(spct_z).count(-1)\n",
    "print(\"DBSCAN\")\n",
    "print(\"\\tnumber of clusters: %d\" % n_clusters_)\n",
    "print(\"\\tnumber of noise points: %d\" % n_noise_)\n",
    "\n",
    "cmap = \"gist_rainbow\" #magma\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"DBSCAN\")\n",
    "plt.scatter(blob_x_train[:,0], blob_x_train[:,1], c=db_z,cmap=cmap, alpha=.4)\n",
    "plt.xlabel(\"r_n\")\n",
    "plt.ylabel(\"r_b\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"SpectralClustering\")\n",
    "plt.scatter(blob_x_train[:,0], blob_x_train[:,1], c=spct_z,cmap=cmap, alpha=.4)\n",
    "for cl in set(spct_z):\n",
    "    [xx,yy] = np.mean(blob_x_train[spct_z==cl],axis=0)\n",
    "    plt.text(xx,yy,str(cl))\n",
    "plt.xlabel(\"r_n\")\n",
    "plt.ylabel(\"r_b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.array([[0,1],[0,2],[1,2]])\n",
    "tha_xyz = interpolated_data[\"thb_xyz\"]\n",
    "tha_xyz_blob = tha_xyz[r_indx]\n",
    "tha_xyz_blob=tha_xyz_blob[blob_indx]\n",
    "classes = set(spct_z)\n",
    "\n",
    "fig,axes = plt.subplots(3,1,figsize=(10,30))\n",
    "for i in range(3):\n",
    "    [u,v] = dims[i]\n",
    "    axes[i].scatter(tha_xyz_blob[:,u], tha_xyz_blob[:,v], c=spct_z,cmap=cmap, alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map classes : 0 is SolarWind, 1: magnetosphere, 2: magnetosheat, 3: inner\n",
    "class_map = {0:[0], 1:[1,6,2],2:[7,5],3:[3,4]}\n",
    "y_spct = map_classes(spct_z, class_map)\n",
    "\n",
    "fig,axes = plt.subplots(3,1,figsize=(10,30))\n",
    "for i in range(3):\n",
    "    [u,v] = dims[i]\n",
    "    earth_circle = plt.Circle([0,0],1,color=\"black\")\n",
    "    axes[i].add_patch(earth_circle)\n",
    "    # axis limits\n",
    "    xmin,xmax=tha_xyz_blob[:,u].min(),tha_xyz_blob[:,u].max()\n",
    "    ymin,ymax=tha_xyz_blob[:,v].min(),tha_xyz_blob[:,v].max()\n",
    "    xmin = ymin = min(xmin,ymin)\n",
    "    xmax = ymax = max(xmax,ymax)\n",
    "    axes[i].set_xlim(xmin,xmax)\n",
    "    axes[i].set_ylim(ymin,ymax)\n",
    "    indx = (np.abs(tha_xyz_blob[:,2]) < 4.)\n",
    "    axes[i].scatter(tha_xyz_blob[indx,u], tha_xyz_blob[indx,v], c=y_spct[indx],cmap=cmap, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "#knn.fit(x_train, y_train)\n",
    "knn.fit(x_train_rand[blob_indx], y_spct)\n",
    "\n",
    "I = np.random.choice(np.arange(y_train.shape[0]), size=100)\n",
    "Y = (x_train[I], y_train[I])\n",
    "f = plt.figure()\n",
    "plot_decision_region(x_train, Y, knn, f.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "#tree.fit(x_train, y_train)\n",
    "tree.fit(x_train_rand[blob_indx], y_spct)\n",
    "\n",
    "f = plt.figure()\n",
    "plot_decision_region(x_train, Y, tree, f.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_poly = SVC(kernel=\"poly\")\n",
    "#svc_poly.fit(x_train, y_train)\n",
    "svc_poly.fit(x_train_rand[blob_indx], y_spct)\n",
    "\n",
    "f = plt.figure()\n",
    "plot_decision_region(x_train, Y, svc_poly, f.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "#svc.fit(x_train_log, y_train)\n",
    "svc.fit(x_train_rand[blob_indx], y_spct)\n",
    "\n",
    "f = plt.figure()\n",
    "plot_decision_region(x_train, Y, svc, f.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(clf, target_dir, dt=1.):\n",
    "    if os.path.exists(target_dir):\n",
    "        os.system(f\"rm -r {target_dir}/*\")\n",
    "    else:\n",
    "        os.system(f\"mkdir -p {target_dir}\")\n",
    "    \n",
    "    offsets = -np.arange(0,4+dt,dt) #[0, -1, -2]\n",
    "    for offset in offsets:\n",
    "        norms = [2,1,0]\n",
    "        fig, axes = plt.subplots(1,1,figsize=(5,5))\n",
    "        axes.set_title(f\"offset : {offset}\")\n",
    "        for i in range(1):\n",
    "            [u,v]=dims[i]\n",
    "            index_slice = (np.abs(tha_xyz[:,norms[i]] - offset) < dt/2)\n",
    "            x_min,x_max = tha_xyz[:,u].min(),tha_xyz[:,u].max()\n",
    "            y_min,y_max = tha_xyz[:,v].min(),tha_xyz[:,v].max()\n",
    "            if not index_slice.size:\n",
    "                continue\n",
    "            axes.set_xlim(x_min,x_max)\n",
    "            axes.set_ylim(y_min,y_max)\n",
    "            axes.scatter(tha_xyz[index_slice,u],tha_xyz[index_slice,v],\n",
    "                    c=clf.predict(x_train[index_slice]),\n",
    "                    marker=\".\",alpha=.1,cmap=cmap)\n",
    "        #plt.tight_layout()\n",
    "        filename = os.path.join(target_dir, f\"offset_{offset}.png\")\n",
    "        plt.savefig(filename)\n",
    "        plt.close(\"all\")\n",
    "\n",
    "target_dir = \"slices\"\n",
    "\n",
    "clfs = [knn, tree, svc, svc_poly]\n",
    "for clf, name in zip(clfs, [\"knn\",\"tree\",\"svc\",\"svc_poly\"]):\n",
    "    plot_slices(clf, os.path.join(target_dir, name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "#idx=(np.abs(tha_xyz[:,2])<.5)\n",
    "ax.scatter(tha_xyz[:,0], tha_xyz[:,1], tha_xyz[:,2], \n",
    "           c=knn.predict(x_train[:]), \n",
    "           marker=\".\",\n",
    "           alpha=.002,\n",
    "           cmap=\"gist_rainbow\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Themis A Ephemeris\n",
    "tha_gse = parameter_data[\"thb_xyz\"]#=spz.get_data(\"amda/tha_xyz\", start_d, stop_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tha_gse_interp = interp1d(tha_gse.time, \n",
    "                          tha_gse.data, \n",
    "                          axis=0, bounds_error=False)\n",
    "#t=pd.date_range(start_t, stop_t,freq=\"1H\").astype(np.int64)/1e9\n",
    "tha_interp_data = tha_gse_interp(t)\n",
    "\n",
    "tha_gse_norm = np.linalg.norm(tha_interp_data, axis=1)\n",
    "indx = (tha_gse_norm <= 1.1)\n",
    "print(100. * np.sum(indx) / t.shape[0], np.sum(indx))\n",
    "\n",
    "plt.figure()\n",
    "a,b = np.log(1+r_n), np.log(1+r_b)\n",
    "#a,b = r_n, r_b\n",
    "a,b = normalize(a), normalize(b)\n",
    "#plt.hist2d(np.log(1+r_n), np.log(1+r_b), bins=100, range=domain_,cmap=cmap)\n",
    "print(cmap)\n",
    "plt.hist2d(a, b, bins=1000, range=None,cmap=\"gist_stern\")\n",
    "#plt.scatter(np.log(1+r_n[indx]),np.log(1+r_b[indx]), c=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt\n",
    "#%matplotlib notebook\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "tha_gse_interp = interp1d(tha_gse.time, \n",
    "                          tha_gse.data, \n",
    "                          axis=0, bounds_error=False)\n",
    "#t=pd.date_range(start_t, stop_t,freq=\"1H\").astype(np.int64)/1e9\n",
    "tha_interp_data = tha_gse_interp(t)\n",
    "\n",
    "# interpolate r_n and r_b at the same time\n",
    "#r_b_new = np.linalg.norm(interpolations[\"tha_bs\"](t), axis=1) / \\\n",
    "#      np.linalg.norm(interpolations[\"imf\"](t), axis=1)\n",
    "\n",
    "#r_n_new = (interpolations[\"tha_n_i\"](t) / interpolations[\"sw_n\"](t)).flatten()\n",
    "\n",
    "duration =1*60 # seconds\n",
    "fps = 60\n",
    "n = t.shape[0]\n",
    "frames = duration * fps\n",
    "step = int(n / frames)\n",
    "interval = int(duration*1000 / frames)\n",
    "\n",
    "indx = np.arange(0, n, step).astype(int)\n",
    "print(indx)\n",
    "\n",
    "print(f\"duration : {duration}\")\n",
    "print(f\"fps      : {fps}\")\n",
    "print(f\"frames   : {frames}\")\n",
    "print(f\"interval : {interval}\")\n",
    "print(f\"step     : {step}\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(4,10))\n",
    "alpha = .3\n",
    "lines = [None for _ in np.arange(15)]\n",
    "dims = [[0,1],[0,2],[1,2]]\n",
    "for i in [0,1,2]:\n",
    "    ii = i * 5\n",
    "    lines[ii], = axes[i].plot([],[])\n",
    "    lines[ii+1], = axes[i].plot([],[],\"+\", c=\"r\",alpha=alpha)\n",
    "    lines[ii+2], = axes[i].plot([],[],\"+\", c=\"g\",alpha=alpha)\n",
    "    lines[ii+3], = axes[i].plot([],[],\"+\", c=\"b\",alpha=alpha)\n",
    "    lines[ii+4], = axes[i].plot([],[],\"+\", c=\"m\",alpha=alpha)\n",
    "    u,v = dims[i]\n",
    "    axes[i].set_xlim(tha_interp_data[:,u].min(),tha_interp_data[:,u].max())\n",
    "    axes[i].set_ylim(tha_interp_data[:,v].min(),tha_interp_data[:,v].max())\n",
    "    axes[i].set_xlabel(\"x\")\n",
    "    axes[i].set_ylabel(\"y\")\n",
    "\n",
    "#axes[3].hist2d(x_train_log[:,0], x_train_log[:,1], bins=1000, range=None,cmap=cmap)\n",
    "#pos_line, = axes[3].plot([],[],\"o\",c=\"y\")\n",
    "#lines.append(pos_line)\n",
    "#line, = ax.plot([],[])\n",
    "#line2, = ax.plot([],[],\"+\", c=\"r\",alpha=alpha)\n",
    "#line3, = ax.plot([],[],\"+\", c=\"g\",alpha=alpha)\n",
    "#line4, = ax.plot([],[],\"+\", c=\"b\",alpha=alpha)\n",
    "\n",
    "print(tha_interp_data[:,0].min(),tha_interp_data[:,0].max())\n",
    "print(tha_interp_data[:,1].min(),tha_interp_data[:,1].max())\n",
    "#raise KeyboardInterrupt\n",
    "\n",
    "#ax.set_xlim(tha_interp_data[:,0].min(),tha_interp_data[:,0].max())\n",
    "#ax.set_ylim(tha_interp_data[:,1].min(),tha_interp_data[:,1].max())\n",
    "\n",
    "frontier_data={0:[],1:[],2:[],3:[]}\n",
    "\n",
    "svm_blob=[]\n",
    "\n",
    "N=24\n",
    "\n",
    "#clf = svc_poly\n",
    "#clf = tree\n",
    "#clf = svc\n",
    "clf = knn\n",
    "\n",
    "axes[0].set_title(clf.__class__.__name__)\n",
    "R= None\n",
    "\n",
    "def animate(i):\n",
    "    global R, dims,frontier_data,clf\n",
    "    \n",
    "    j = indx[i]\n",
    "    #print(j)\n",
    "    #print(f\"j:{j}\")\n",
    "    if j>N:\n",
    "        x, y = tha_interp_data[j-N:j,0], tha_interp_data[j-N:j,1]\n",
    "        X = tha_interp_data[j-N:j,:]\n",
    "    else:\n",
    "        x, y = tha_interp_data[:j,0], tha_interp_data[:j,1]\n",
    "        X = tha_interp_data[:j,:]\n",
    "    #print(r_b_new[i], r_n_new[i])\n",
    "    xnew = np.array([[r_n_norm[j], r_b_norm[j]]])\n",
    "    #print(xnew)\n",
    "    \n",
    "    if not np.any(np.isnan(xnew)):\n",
    "        #xnew = np.log(1+xnew)\n",
    "        p=clf.predict(xnew)[0]\n",
    "        \n",
    "        if R is None:\n",
    "            R = int(p)\n",
    "            if not R in frontier_data:\n",
    "                frontier_data[R] = []\n",
    "            \n",
    "            #frontier_data[R].append(tha_interp_data[j,:])\n",
    "                \n",
    "        else:\n",
    "            if int(p)!=R:\n",
    "                nR=int(p)\n",
    "                if not nR in frontier_data:\n",
    "                    frontier_data[nR] = []\n",
    "                #frontier_data[nR].append(tha_interp_data[j,:])\n",
    "                #frontier_data[R].append(tha_interp_data[j-1,:])\n",
    "                R = int(p)\n",
    "        frontier_data[R].append(tha_interp_data[j,:])\n",
    "        #frontier_data[R][1].append(tha_interp_data[j,1])\n",
    "        \n",
    "        for l in [0,1,2]:\n",
    "            ii=l*5\n",
    "            #print(l, dims[l], X)\n",
    "            [u,v] = dims[l]\n",
    "            if X.size:\n",
    "                lines[ii].set_data(X[:,u],X[:,v])\n",
    "            \n",
    "            if len(frontier_data[0]):\n",
    "                tt = np.array(frontier_data[0])\n",
    "                uu,vv = dims[0]\n",
    "                lines[ii+1].set_data(tt[:,u],tt[:,v])\n",
    "            if len(frontier_data[1]):\n",
    "                tt = np.array(frontier_data[1])\n",
    "                uu,vv = dims[1]\n",
    "                lines[ii+2].set_data(tt[:,u],tt[:,v])\n",
    "            if len(frontier_data[2]):\n",
    "                tt = np.array(frontier_data[2])\n",
    "                uu,vv = dims[2]\n",
    "                lines[ii+3].set_data(tt[:,u],tt[:,v])\n",
    "            if len(frontier_data[3]):\n",
    "                tt = np.array(frontier_data[3])\n",
    "                lines[ii+4].set_data(tt[:,u],tt[:,v])\n",
    "        if np.linalg.norm(X)<4:\n",
    "            svm_blob.append(xnew)\n",
    "        #line2.set_data(frontier_data[0][0],frontier_data[0][1])\n",
    "        #line3.set_data(frontier_data[1][0],frontier_data[1][1])\n",
    "        #line4.set_data(frontier_data[2][0],frontier_data[2][1])\n",
    "        #lines[12].set_data([xnew[0,0]],[xnew[0,1]])\n",
    "        \n",
    "    \n",
    "    #line.set_data(X[u],X[v])\n",
    "    return tuple(lines)\n",
    "    return line,line2,line3,line4\n",
    "\n",
    "#for i in np.arange(1000):\n",
    "#    animate(i)\n",
    "ani = animation.FuncAnimation(fig, animate, frames=frames, blit=True, \n",
    "                             interval=interval,\n",
    "                          repeat=False)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for clf in clfs:\n",
    "    predictions.append(clf.predict(x_train))\n",
    "    if len(predictions)>1:\n",
    "        for p in predictions:\n",
    "            print(clf.__class__.__name__, np.sum(p != predictions[-1]))\n",
    "\n",
    "m = len(clfs)\n",
    "fig, axes = plt.subplots(m,m,sharex=True,sharey=True)\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        if i!=j:\n",
    "            axes[i,j].hist(predictions[i][predictions[i] != predictions[j]], alpha=.5, density=True)\n",
    "            axes[i,j].hist(predictions[j][predictions[i] != predictions[j]], alpha=.5, density=True)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolating on slices\n",
    "indx = (np.abs(tha_xyz[:,2]) < .4)\n",
    "print(\"npoints \", np.sum(indx))\n",
    "# position data\n",
    "pos_data = tha_xyz[indx]\n",
    "# predictions\n",
    "pred_data = predictions[0][indx]\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.tricontour(pos_data[:,0], pos_data[:,1], pred_data, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp2d\n",
    "\n",
    "print(pos_data.shape[0])\n",
    "rindx = np.random.choice(range(pos_data.shape[0]), size=2000)\n",
    "rindx = np.arange(0, pos_data.shape[0], 5)\n",
    "\n",
    "ii = interp2d(pos_data[rindx,0], pos_data[rindx,1], pred_data[rindx],\n",
    "             kind=\"linear\")\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mcl,Mcl = pred_data.min(), pred_data.max()\n",
    "xmin,xmax=pos_data[:,0].min(),pos_data[:,1].max()\n",
    "ymin,ymax=pos_data[:,1].min(),pos_data[:,1].max()\n",
    "xx = np.linspace(xmin, xmax, 1000)\n",
    "yy = np.linspace(ymin, ymax, 1000)\n",
    "#xx, yy = np.meshgrid(xx, yy)\n",
    "plt.figure(figsize=(10,10))\n",
    "ttt={0:\"r\",1:\"g\",2:\"b\",3:\"m\"}\n",
    "#cmap = (mpl.colors.ListedColormap(['r', 'g', 'b', 'm']))\n",
    "#        .with_extremes(over='0.25', under='0.75'))\n",
    "#bounds = [0, 1, 2, 3, 4]\n",
    "#norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cmap = mpl.colors.ListedColormap(['r','g','b','m'])\n",
    "cs = plt.gca().contourf(xx, yy, \n",
    "                        np.clip(ii(xx,yy), mcl, Mcl).astype(int),\n",
    "                       cmap=cmap)\n",
    "#fig.colorbar(cs, ax=plt.gca(), shrink=0.9)\n",
    "fig.colorbar(\n",
    "    mpl.cm.ScalarMappable(cmap=cmap),\n",
    "    ax=plt.gca(),\n",
    "    #boundaries=[0] + bounds + [13],  # Adding values for extensions.\n",
    "    #extend='both',\n",
    "    #ticks=bounds,\n",
    "    spacing='proportional',\n",
    "    orientation='vertical',\n",
    "    #label='Discrete intervals, some other units',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate r_n and r_b \n",
    "R=5.\n",
    "xx, yy = np.linspace(-R,R,1000), np.linspace(-R,R,1000)\n",
    "zz_r_n = interp2d(pos_data[rindx,0], pos_data[rindx,1], r_n_norm[rindx],\n",
    "             kind=\"cubic\")\n",
    "zz_r_b = interp2d(pos_data[rindx,0], pos_data[rindx,1], r_b_norm[rindx],\n",
    "             kind=\"cubic\")\n",
    "\n",
    "#temp_z = np.vstack((r_n_norm[rindx],r_b_norm[rindx])).T\n",
    "#print (f\"temp_z.shape : {temp_z.shape}\")\n",
    "\n",
    "#zz_r = interp2d(pos_data[rindx,0], pos_data[rindx,1],temp_z)\n",
    "\n",
    "fig, axes = plt.subplots(2,1,figsize=(10,20))\n",
    "#axes[0].set_xlim(0,10)\n",
    "#axes[0].set_ylim(0,10)\n",
    "cs0 = axes[0].contourf(xx,yy,zz_r_n(xx,yy),cmap=\"gist_rainbow\")\n",
    "#axes[1].set_xlim(0,10)\n",
    "#axes[1].set_ylim(0,10)\n",
    "cs1 = axes[1].contourf(xx,yy,zz_r_b(xx,yy),cmap=\"gist_rainbow\")\n",
    "fig.colorbar(cs0, ax=axes[0])\n",
    "fig.colorbar(cs1, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsh = zz_r_n(xx,yy).shape\n",
    "zz_x = np.c_[zz_r_n(xx,yy).ravel(),zz_r_b(xx,yy).ravel()]\n",
    "\n",
    "fig, axes =plt.subplots(m,1,figsize=(10,m*10))\n",
    "for i in range(m):\n",
    "    name = clfs[i].__class__.__name__\n",
    "    print(i, name)\n",
    "    pp = clfs[i].predict(zz_x).reshape(tsh)\n",
    "    axes[i].set_title(name)\n",
    "    #cmap = mpl.colors.ListedColormap(['r','g','b','m'])\n",
    "    cs=axes[i].contourf(xx,yy,pp,cmap=cmap)\n",
    "    earth_circle = plt.Circle([0,0],1,color=\"black\")\n",
    "    axes[i].add_patch(earth_circle)\n",
    "    fig.colorbar(cs,ax=axes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure()\n",
    "plt.hist2d(x_train_log[:,0], x_train_log[:,1], bins=1000, range=None,cmap=cmap)\n",
    "x_svm_blob = np.array(svm_blob)\n",
    "print(x_svm_blob.shape)\n",
    "plt.scatter(x_svm_blob[:,0], x_svm_blob[:,1],\".\",c=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import constants as cst\n",
    "\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    r = np.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "    theta = np.arccos(x / r)\n",
    "    phi = np.arctan2(y, z)\n",
    "    phi[z==0]=np.sign(y[z==0])*np.pi/2\n",
    "    return r, theta, phi\n",
    "\n",
    "def spherical_to_cartesian(r, theta, phi):\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta) * np.sin(phi)\n",
    "    z = r * np.sin(theta) * np.cos(phi)\n",
    "    return x, y, z\n",
    "\n",
    "def choice_coordinate_system(R, theta, phi, **kwargs):\n",
    "    coord_sys = kwargs.get('coord_sys','cartesian')\n",
    "    if coord_sys == 'cartesian':\n",
    "        return spherical_to_cartesian(R, theta, phi)\n",
    "    elif coord_sys == 'spherical':\n",
    "        return R, theta, phi\n",
    "    else:\n",
    "        print('Error : coord_sys parameter must be set to \"cartesian\" or \"spherical\" ')\n",
    "\n",
    "def bs_Jerab2005(theta, phi, **kwargs):\n",
    "    '''\n",
    "    Jerab 2005 Bow shock model. Give positions of the box shock in plans (XY) with Z=0 and (XZ) with Y=0 as a function of the upstream solar wind.\n",
    "    function's arguments :\n",
    "        - Np : Proton density of the upstream conditions\n",
    "        - V  : Speed of the solar wind\n",
    "        - B  : Intensity of interplanetary magnetic field\n",
    "        - gamma : Polytropic index ( default gamma=2.15)\n",
    "        --> mean parameters :  Np=7.35, V=425.5,  B=5.49\n",
    "     return : DataFrame (Pandas) with the position (X,Y,Z) in Re of the bow shock to plot (XY) and (XZ) plans.\n",
    "    '''\n",
    "\n",
    "    def make_Rav(theta, phi):\n",
    "        a11 = 0.45\n",
    "        a22 = 1\n",
    "        a33 = 0.8\n",
    "        a12 = 0.18\n",
    "        a14 = 46.6\n",
    "        a24 = -2.2\n",
    "        a34 = -0.6\n",
    "        a44 = -618\n",
    "\n",
    "        x = np.cos(theta)\n",
    "        y = np.sin(theta) * np.sin(phi)\n",
    "        z = np.sin(theta) * np.cos(phi)\n",
    "\n",
    "        a = a11 * x ** 2 +  a22 * y ** 2 + a33 * z ** 2 + a12 * x * y\n",
    "        b = a14 * x + a24 * y + a34 * z\n",
    "        c = a44\n",
    "\n",
    "        delta = b ** 2 - 4 * a * c\n",
    "\n",
    "        R = (-b + np.sqrt(delta)) / (2 * a)\n",
    "        return R\n",
    "\n",
    "    Np = kwargs.get('Np', 6.025)\n",
    "    V = kwargs.get('V', 427.496)\n",
    "    B = kwargs.get('B', 5.554)\n",
    "    gamma = kwargs.get('gamma', 5./3)\n",
    "    Ma = V * 1e3 * np.sqrt(Np * 1e6 * cst.m_p * cst.mu_0) / (B * 1e-9)\n",
    "\n",
    "    C = 91.55\n",
    "    D = 0.937 * (0.846 + 0.042 * B)\n",
    "    R0 = make_Rav(0, 0)\n",
    "\n",
    "    Rav = make_Rav(theta, phi)\n",
    "    K = ((gamma - 1) * Ma ** 2 + 2) / ((gamma + 1) * (Ma ** 2 - 1))\n",
    "    r = (Rav / R0) * (C / (Np * V ** 2) ** (1 / 6)) * (1 + D * K)\n",
    "\n",
    "    return choice_coordinate_system(r, theta, phi, **kwargs)        \n",
    "\n",
    "def mp_shue1997(theta, phi, **kwargs):\n",
    "    Pd = kwargs.get(\"Pd\", 1.82) #2.056)\n",
    "    Bz = kwargs.get(\"Bz\", -0.001)\n",
    "\n",
    "    if isinstance(Bz, float) | isinstance(Bz, int):\n",
    "        if Bz >= 0:\n",
    "            r0 = (11.4 + 0.13 * Bz) * Pd ** (-1 / 6.6)\n",
    "        else:\n",
    "            r0 = (11.4 + 0.14 * Bz) * Pd ** (-1 / 6.6)\n",
    "    else:\n",
    "        if isinstance(Pd, float) | isinstance(Pd, int):\n",
    "            Pd = np.ones_like(Bz) * Pd\n",
    "        r0 = (11.4 + 0.13 * Bz) * Pd ** (-1 / 6.6)\n",
    "        r0[Bz < 0] = (11.4 + 0.14 * Bz[Bz < 0]) * Pd[Bz < 0] ** (-1 / 6.6)\n",
    "    a = (0.58 - 0.010 * Bz) * (1 + 0.010 * Pd)\n",
    "    r = r0 * (2. / (1 + np.cos(theta))) ** a\n",
    "    return choice_coordinate_system(r, theta, phi, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = np.linspace(0, np.pi/4 , 1)\n",
    "plt.figure()\n",
    "earth = plt.Circle((0,0),1,color=\"black\")\n",
    "plt.gca().add_patch(earth)\n",
    "\n",
    "for ph in phis:\n",
    "    theta, phi = np.linspace(0, 2*np.pi, 100), ph*np.ones(100)\n",
    "    x,y,z = mp_shue1997(theta, phi)\n",
    "\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    plt.plot(x,z)\n",
    "    x,y,z = bs_Jerab2005(theta, phi)\n",
    "    plt.plot(x,z,\"--\")\n",
    "\n",
    "plt.xlim([-30,30])\n",
    "plt.ylim([-30,30])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "indx = (np.abs(tha_xyz_blob[:,2]) < 3)\n",
    "tha_x = tha_xyz_blob[indx]\n",
    "\n",
    "xmin,xmax = tha_x[:,0].min(), tha_x[:,0].max()\n",
    "ymin,ymax = tha_x[:,1].min(), tha_x[:,1].max()\n",
    "\n",
    "x,y,z = mp_shue1997(theta, np.zeros(100))\n",
    "plt.plot(x,z,\"black\")\n",
    "x,y,z = bs_Jerab2005(theta, phi)\n",
    "plt.plot(x,z,\"--\",c=\"black\")\n",
    "plt.scatter(tha_x[:,0], tha_x[:,1], c=spct_z[indx],cmap=cmap, alpha=.3)\n",
    "plt.xlim([xmin,xmax])\n",
    "plt.ylim([ymin,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_class(x):\n",
    "    # spherical coordinates\n",
    "    r,theta,phi = cartesian_to_spherical(x[:,0],x[:,1],x[:,2])\n",
    "    # bow shock\n",
    "    bs_x, bs_y, bs_z = bs_Jerab2005(theta, phi)\n",
    "    bs_dist = np.linalg.norm(np.vstack((bs_x,bs_y,bs_z)).T, axis=1)\n",
    "    # magnetopause\n",
    "    mp_x, mp_y, mp_z = mp_shue1997(theta, phi)\n",
    "    mp_dist = np.linalg.norm(np.vstack((mp_x,mp_y,mp_z)).T, axis=1)\n",
    "    \n",
    "    # x norm\n",
    "    x_dist = np.linalg.norm(x, axis=1)\n",
    "    \n",
    "    ans = np.zeros(x.shape[0]).astype(int)\n",
    "    ans[x_dist <= mp_dist] = 1 # magnetoshere\n",
    "    ans[(mp_dist < x_dist) & (x_dist <= bs_dist)] = 2 # magnetosheath\n",
    "    ans[bs_dist < x_dist] = 0 # solar wind\n",
    "    \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real labels\n",
    "real_labels = get_position_class(tha_xyz)\n",
    "\n",
    "fig = plt.figure()\n",
    "#indx = (np.abs(tha_xyz_blob[:,2]) < 3)\n",
    "#tha_x = tha_xyz_blob[indx]\n",
    "\n",
    "xmin,xmax = tha_xyz[:,0].min(), tha_xyz[:,0].max()\n",
    "ymin,ymax = tha_xyz[:,1].min(), tha_xyz[:,1].max()\n",
    "\n",
    "x,y,z = mp_shue1997(theta, np.zeros(100))\n",
    "plt.plot(x,z,\"black\")\n",
    "x,y,z = bs_Jerab2005(theta, np.zeros(100))\n",
    "plt.plot(x,z,\"--\",c=\"black\")\n",
    "plt.scatter(tha_xyz[:,0], tha_xyz[:,1], c=real_labels,cmap=cmap, alpha=.1)\n",
    "plt.xlim([xmin,xmax])\n",
    "plt.ylim([ymin,ymax])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x__ = np.vstack((r_n_norm,r_b_norm)).T\n",
    "pred_labels = knn.predict(x__)\n",
    "print(np.sum(pred_labels == 0))\n",
    "print(np.sum(pred_labels == 1))\n",
    "print(np.sum(pred_labels == 2))\n",
    "print(np.sum(pred_labels == 3))\n",
    "print(pred_labels.shape[0])\n",
    "print()\n",
    "pred_labels = np.where(pred_labels==3, 1, pred_labels)\n",
    "\n",
    "# correct sw\n",
    "sw_indx = (pred_labels==0)\n",
    "eps = .1\n",
    "sw_one = (r_b <= 1. + eps)\n",
    "print(sw_indx.shape, sw_one.shape)\n",
    "print(\"aa  \",np.sum(sw_one), np.sum(sw_indx), np.sum(sw_indx & sw_one))\n",
    "#pred_labels[sw_indx & sw_one] = 1\n",
    "print(np.sum(pred_labels == 0))\n",
    "print(np.sum(pred_labels == 1))\n",
    "print(np.sum(pred_labels == 2))\n",
    "print(np.sum(pred_labels == 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "print(f\"Accuracy  : {accuracy_score(real_labels, pred_labels)}\")\n",
    "print(f\"Precision : {precision_score(real_labels, pred_labels,average='macro')}\")\n",
    "print(f\"Recall    : {recall_score(real_labels, pred_labels,average='macro')}\")\n",
    "print(f\"F1-score  : {f1_score(real_labels, pred_labels,average='macro')}\")\n",
    "print(np.sum(real_labels != pred_labels))\n",
    "print(np.sum(pred_labels == 2))\n",
    "ConfusionMatrixDisplay.from_predictions(real_labels, pred_labels,normalize=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering\n",
    "N = r_b.shape[0]\n",
    "\n",
    "def cluster_recursive(x, xyz, n_clusters=5):\n",
    "    if n_clusters <= 0:\n",
    "        return []\n",
    "    if x.shape[0] < n_clusters:\n",
    "        return []\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    pred = kmeans.fit_predict(x)\n",
    "    classes = set(pred)\n",
    "    pure_classes = []\n",
    "    for cl in classes:\n",
    "        pos_class = get_position_class(xyz[pred==cl])\n",
    "        unq = np.unique(pos_class)\n",
    "        if unq.size==1:\n",
    "            nshape = (np.sum(pred==cl), 2)\n",
    "            lshape = np.sum(pred==cl)\n",
    "            pure_classes.append((x[pred==cl].reshape(nshape), pos_class.reshape(lshape)))\n",
    "        else:\n",
    "            # more then one class in this cluster\n",
    "            p = cluster_recursive(x[pred==cl], xyz[pred==cl], n_clusters=n_clusters-1)\n",
    "            if len(p)==0:\n",
    "                nshape = (np.sum(pred==cl), 2)\n",
    "                lshape = np.sum(pred==cl)\n",
    "                pure_classes.append((x[pred==cl].reshape(nshape), pos_class.reshape(lshape)))\n",
    "            else:\n",
    "                for pp in p:\n",
    "                    pure_classes.append(pp)\n",
    "\n",
    "    c0 = pure_classes.pop(0)\n",
    "    xx,yy = c0[0],c0[1]\n",
    "    while len(pure_classes):\n",
    "        pp = pure_classes.pop(0)\n",
    "        xx = np.vstack((xx,pp[0]))\n",
    "        yy = np.hstack((yy,pp[1]))\n",
    "        \n",
    "    return [(xx,yy)]\n",
    "            \n",
    "\n",
    "indx = np.random.choice(range(N), 5000)\n",
    "indx = np.arange(0, N, 100)\n",
    "X = np.vstack((r_n,r_b)).T\n",
    "[(a,b)]=cluster_recursive(X[indx], tha_xyz[indx])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[indx,0], X[indx,1], c=b)\n",
    "plt.xlim([0,30])\n",
    "plt.ylim([0,30])\n",
    "\n",
    "fig=plt.figure()\n",
    "cs=plt.scatter(np.log(1+X[indx,0]), np.log(1+X[indx,1]), c=b)\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([0,6])\n",
    "plt.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = get_position_class(tha_xyz)\n",
    "\n",
    "N = r_b.shape[0]\n",
    "X = np.vstack((r_n,r_b)).T\n",
    "\n",
    "knn2 = KNeighborsClassifier()\n",
    "indx = np.arange(0, N, 1000)\n",
    "knn2.fit(X[indx], real_labels[indx])\n",
    "fig = plt.figure()\n",
    "plot_decision_region(X[indx], None, knn2, f.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speasy_examples",
   "language": "python",
   "name": "speasy_examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
